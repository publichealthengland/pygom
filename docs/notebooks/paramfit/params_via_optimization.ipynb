{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Estimation: Maximum likelihood\n",
    "\n",
    "In the previous section, we outlined how to use Markov Chain Monte Carlo methods to estimate the posterior probability distribution of parameters.\n",
    "These methods have generally replaced techniques which infer the maximum likelihood estimates (MLE) of parameter values, with confidence levels provided after making assumptions about the local likelihood landscape.\n",
    "PyGOM has the capability to estimate parameters in this way and although perhaps outdated, including these methods could still be practical if trying to reproduce work from older publications, for example.\n",
    "\n",
    "## Example: SEIR model (with I and R known)\n",
    "\n",
    "We now solve the same problem as in the previous section, this time via minimisation of the cost function.\n",
    "As a reminder: We have data from an SEIR system where the time series of $I$ and $R$ are known and we wish to estimate parameters $\\beta$, $\\alpha$ and $\\gamma$ with true values 0.35, 0.5 and 0.25 respectively.\n",
    "We assume that the total population, $N=10,000$ and the initial number infecteds, $i_0=5$, are both known.\n",
    "\n",
    "We start by loading the data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efea520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "import numpy as np\n",
    "\n",
    "out = np.loadtxt('seir_epi_data.txt')\n",
    "t=out[:,0]\n",
    "sol_i_r=out[:,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c30e7",
   "metadata": {},
   "source": [
    "The syntax for setting up the solver is similar to the approach via ABC.\n",
    "We first form our candidate SEIR model.\n",
    "Currently, PyGOM requires us to provide numerical values for all model parameters, including the unknown ones we are trying to estimate.\n",
    "These values are used to perform an additional prior check to verify that the function provided is integrable.\n",
    "This step will be likely removed for later versions, but for now it's probably best to input initial guesses as parameter values.\n",
    "For the current example, this means specifying $\\beta$, $\\alpha$ and $\\gamma$ from our initial guess `theta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857371e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygom import common_models\n",
    "\n",
    "n_pop=1e4                # known population size\n",
    "theta = [0.4, 0.3, 0.3]  # initial guess for [beta, alpha, gamma]\n",
    "\n",
    "paramEval=[('beta', theta[0]), ('alpha', theta[1]), ('gamma', theta[2]), ('N', n_pop)]\n",
    "ode_SEIR = common_models.SEIR_N(param=paramEval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c83797",
   "metadata": {},
   "source": [
    "We pass all other required information, including initial conditions, `x0`, to build an object of class {class}`.PoissonLoss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88ad9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "i0=5\n",
    "x0=[n_pop-i0, 0, i0, 0]  # initial conditions\n",
    "\n",
    "from pygom import PoissonLoss\n",
    "\n",
    "objSEIR = PoissonLoss(theta, ode_SEIR,\n",
    "                      t0=t[0], x0=x0,\n",
    "                      t=t[1:], y=sol_i_r[1:,:],\n",
    "                      target_param=['beta', 'alpha', 'gamma'],\n",
    "                      state_name= ['I', 'R'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabcb9ba",
   "metadata": {},
   "source": [
    "```{note}\n",
    "It is a good idea to check that value of $R_0$ corresponding to the initial guess is greater than 1.\n",
    "For instance, here $\\frac{\\beta}{\\gamma}=\\frac{0.4}{0.3}=1.33$.\n",
    "This is important because if $R_0<1$ then the resulting model output will be an exponential decay - essentially, a failed epidemic which will differ substantially from the data.\n",
    "If the optimization algorithm proceeds by attempting new sets of parameters in the neighbourhood of the initial ones, these are also likely to result in similarly bad model fits and the algorithm may not find a way out.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a5020",
   "metadata": {},
   "source": [
    "## Gradient calculations\n",
    "\n",
    "How the parameter optimizer will navigate parameter space will depend on the gradient of the cost function with respect to the parameters.\n",
    "PyGOM can calculate the gradient in two different ways.\n",
    "First, let's compare the outputs of the two methods when evaluated at the initial condition, `theta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de043dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(objSEIR.sensitivity())\n",
    "print(objSEIR.adjoint())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c6356",
   "metadata": {},
   "source": [
    "Also, let's compare the times each method takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit objSEIR.sensitivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20856aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit objSEIR.adjoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a86770d",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Note how we ran the two gradient functions once before timing it, that is because we only find the properties (Jacobian, gradient) of the ODEs during runtime.\n",
    "\n",
    "The amount of time taken for both methods is dependent on the number of observations as well as the number of states.\n",
    "The effect on the adjoint method as the number of observations differs can be quite evident.\n",
    "This is because the adjoint method is under a discretization which loops in Python where as the forward sensitivity equations are solved via an integration.\n",
    "As the number of observation gets larger, the affect of the Python loop becomes more obvious.\n",
    "\n",
    "The difference in gradient is larger when there are less observations.\n",
    "This is because the adjoint method use interpolations on the output of the ode between each consecutive time points.\n",
    "Given solutions over the same length of time, fewer discretizations leads to a less accurate interpolation.\n",
    "Note that the interpolation is currently performed using a univariate spline, due to the limitation of Python packages.\n",
    "Ideally, one would prefer to use an (adaptive) Hermite or Chebyshev interpolation.\n",
    "\n",
    "#TODO refs or just leave this out?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ec840",
   "metadata": {},
   "source": [
    "## Optimised result\n",
    "\n",
    "We now employ optimisation procedures which should progress from the initial guess (if the initial guess is sensible enough) to the parameter set which minimises our cost function.\n",
    "It is particularly important to set the boundaries for the parameters here, since we know that they are required to be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff093f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxBounds = [(0.0,2.0), (0.0,2.0), (0.0,2.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7590328f",
   "metadata": {},
   "source": [
    "Now we use the *SLSQP* optimization routine of `scipy.optimize` with gradient obtained by forward sensitivity.\n",
    "\n",
    "We could, of course, use other methods available in `scipy.optimize.minimize`, such as *L-BFGS-B* and *TNC*.\n",
    "We can also use methods that accepts the exact Hessian such as *trust-ncg* but that should not be necessary most of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eca0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "res = minimize(fun=objSEIR.cost,\n",
    "               jac=objSEIR.sensitivity,\n",
    "               x0=theta, \n",
    "               bounds=boxBounds,\n",
    "               method='SLSQP')\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912700fc",
   "metadata": {},
   "source": [
    "We see that parameter values are in agreement with the underlying model and there is visual agreement with data when plotted below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c826a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars=res.x\n",
    "\n",
    "ode_est = common_models.SEIR_N([('beta', pars[0]), ('alpha', pars[1]), ('gamma', pars[2]), ('N', n_pop)])\n",
    "ode_est.initial_values = (x0, t[0])\n",
    "solution = ode_est.integrate(t[1::])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "f, axarr = plt.subplots(1,2, layout='constrained', figsize=(10, 2.5))\n",
    "\n",
    "axarr[0].plot(t, sol_i_r[:,0], color='C0')\n",
    "axarr[0].plot(t, solution[:,2], color='C1')\n",
    "axarr[1].plot(t, sol_i_r[:,1], color='C0')\n",
    "axarr[1].plot(t, solution[:,3], color='C1');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d99fc",
   "metadata": {},
   "source": [
    "## Confidence intervals of estimated parameters\n",
    "\n",
    "Point estimates of parameters found via MLE provide the *best* fit, but are incomplete without some measure of their uncertainty.\n",
    "With the ABC method of the previous section, credible intervals fall out as part of the fitting process, since the output is parameter probability distributions.\n",
    "For parameter estimates found via optimisation, we need to make some assumptions about the shape of the likelihood function in the neighbourhood of the MLE to obtain confidence levels.\n",
    "\n",
    "```{warning}\n",
    "PyGOM has built in functions using different methods to solve this problem; these are, however, under development.\n",
    "The location and names of the relevant code can be found below and they should be carefully inspected before being employed.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pygom import confidence_interval as ci\n",
    "\n",
    "## Different methods for CIs:\n",
    "# ci.asymptotic\n",
    "# ci.profile\n",
    "# ci.bootstrap\n",
    "# ci.geometric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('sphinx-doc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "4dc1e323c80fe09539c74ad5c5a7c7d8d9ff99e04f7b3dbd3680daf878629d6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
